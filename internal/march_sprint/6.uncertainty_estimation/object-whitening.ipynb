{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fdc696-7675-4e82-a56b-f29dacda2879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --quiet git+https://github.com/astronomy-commons/hats.git@main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9011481c-b17c-4b28-a90a-1d7514324bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --quiet git+https://github.com/astronomy-commons/lsdb.git@main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6911d11b-f42d-4a9f-bfe2-9348572b9e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsdb\n",
    "\n",
    "lsdb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b19605-d53f-4895-b77e-8e6df8081664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "import lsdb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask\n",
    "\n",
    "from dask.distributed import Client\n",
    "from nested_pandas.utils import count_nested\n",
    "from dask.distributed import print as dask_print\n",
    "from lsdb.core.search.pixel_search import PixelSearch\n",
    "from lsdb.core.search.order_search import OrderSearch\n",
    "from io import StringIO\n",
    "from nested_pandas import NestedDtype\n",
    "from pathlib import Path\n",
    "from hats.pixel_math import HealpixPixel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ff832b-5d94-4b88-bf41-b8f6e84b7fb2",
   "metadata": {},
   "source": [
    "This is pretty brute-force. I gave up on thinking about how to make the reuslts per-band co-exist in the same table, and I'm just running the stages 6 times, once for each band.\n",
    "\n",
    "I might need to do it differently for diaObject, but we'll see what happens tomorrow!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2259af0-7c2d-4618-9fa6-adcf2a93d5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_decomposition(a):\n",
    "    n = len(a)\n",
    "    D = np.diag(a)\n",
    "    one_vec = np.ones((n, 1)) / np.sqrt(n)\n",
    "\n",
    "    inv_a_sum = np.sum(1/a)\n",
    "    u = np.ones((n, 1)) / np.sqrt(inv_a_sum)\n",
    "\n",
    "    # Explicit eigenvalue along ones-vector:\n",
    "    lambda_min = float((one_vec.T @ (D - u @ u.T) @ one_vec).item())\n",
    "    assert lambda_min > 0\n",
    "\n",
    "    # Construct orthonormal basis explicitly:\n",
    "    Q, _ = np.linalg.qr(np.eye(n) - one_vec @ one_vec.T)\n",
    "    Q = Q[:, :n-1]  # explicitly enforce correct dimensions (n x n-1)\n",
    "\n",
    "    # Project onto orthogonal subspace:\n",
    "    M_orth = Q.T @ (D - u @ u.T) @ Q\n",
    "    eigvals_orth, eigvecs_orth = np.linalg.eigh(M_orth)\n",
    "    assert np.all(eigvals_orth > 0)\n",
    "\n",
    "    # Combine eigenvectors/eigenvalues explicitly:\n",
    "    eigvals_full = np.concatenate(([lambda_min], eigvals_orth))\n",
    "    eigvecs_full = np.hstack((one_vec, Q @ eigvecs_orth))\n",
    "\n",
    "    # Cholesky-like decomposition\n",
    "    B = eigvecs_full @ np.diag(np.sqrt(eigvals_full))\n",
    "\n",
    "    return B\n",
    "\n",
    "\n",
    "def whiten_data(x, sigma):\n",
    "    mu = np.average(x, weights=1 / sigma**2)\n",
    "\n",
    "    decomposed = stable_decomposition(sigma**2)\n",
    "    transform = np.linalg.inv(decomposed)\n",
    "\n",
    "    residual = x - mu\n",
    "    z = transform @ residual\n",
    "\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf6d139-2b54-4bac-9a3f-1a503954ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_nested(nested_df, pixel, source_column, band):\n",
    "    dask_print(\"starting on\", pixel)\n",
    "    empty_result = {\n",
    "        \"max_variability\": np.float64,\n",
    "        \"band\": \"str\",\n",
    "        \"wmean_flux\": np.float64,\n",
    "        \"rel_dev\": pd.Series([], dtype=np.float64),\n",
    "        \"whitened_data\": pd.Series([], dtype=np.float64),\n",
    "    }\n",
    "    nested_df = nested_df.assign(\n",
    "        **{\n",
    "            source_column: nested_df[source_column].astype(\n",
    "                NestedDtype.from_pandas_arrow_dtype(nested_df.dtypes[source_column])\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    ## Consider only lightcurves in the target band\n",
    "    nested_df = nested_df.query(\n",
    "        f\"{source_column}.band == '{band}' and not {source_column}.psfFlux_flag\"\n",
    "    ).dropna(subset=source_column)\n",
    "    if len(nested_df) == 0:\n",
    "        dask_print(\"found nothing in band\")\n",
    "        return empty_result\n",
    "\n",
    "    ## Needs to have at least 10 observations in that band\n",
    "    counts = count_nested(nested_df, source_column)\n",
    "    nested_df = nested_df.loc[counts[f\"n_{source_column}\"] > 10]\n",
    "    if len(nested_df) == 0:\n",
    "        dask_print(\"all lightcurves too short\")\n",
    "        return empty_result\n",
    "\n",
    "    def rate_variability(flux_column, flux_err_columns):\n",
    "        wmean_flux = np.average(flux_column, weights=1 / flux_err_columns**2)\n",
    "        rel_dev = (flux_column - wmean_flux) / flux_err_columns\n",
    "\n",
    "        return {\n",
    "            \"max_variability\": np.abs(rel_dev).max(),\n",
    "            \"band\": band,\n",
    "            \"wmean_flux\": wmean_flux,\n",
    "            \"rel_dev\": rel_dev,\n",
    "            \"whitened_data\": whiten_data(flux_column, flux_err_columns)\n",
    "        }\n",
    "\n",
    "    ## Drop rows with obvious variability, just return stats per-object.\n",
    "    z_scores = nested_df.reduce(\n",
    "        rate_variability, f\"{source_column}.psfFlux\", f\"{source_column}.psfFluxErr\"\n",
    "    )\n",
    "    non_vars = z_scores.query(\"max_variability < 10\")\n",
    "    if len(non_vars) == 0:\n",
    "        dask_print(\"all lightcurves too variable\")\n",
    "        return empty_result\n",
    "\n",
    "    dask_print(\"worked on\", pixel, \"found\", len(non_vars))\n",
    "    return non_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023303dd-9487-4e28-944c-401ca9a6b7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "drp_release = \"w_2025_11\"\n",
    "hats_dir = Path(\"/sdf/data/rubin/shared/lsdb_commissioning/hats\")\n",
    "hats_path = hats_dir / drp_release\n",
    "output_path = Path(\n",
    "    \"/sdf/data/rubin/shared/lsdb_commissioning/science_projects/06_uncertainty/object_whiten\"\n",
    ")\n",
    "target_source_column = \"objectForcedSource\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6c8613-cca6-458c-8785-76004abd47da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_band in [\"g\", \"r\", \"i\", \"z\"]:\n",
    "    # Create a local cluster and connect to it\n",
    "    with Client(n_workers=1, threads_per_worker=1, memory_limit=\"10GB\") as client:\n",
    "        dask.config.set({\"dataframe.convert-string\": False})\n",
    "        \n",
    "        object_catalog = lsdb.read_hats(\n",
    "            hats_path / \"object_lc\", columns=[\"objectId\", target_source_column]\n",
    "        )\n",
    "        obj_cat = object_catalog.map_partitions(\n",
    "            filter_by_nested,\n",
    "            source_column=target_source_column,\n",
    "            band=target_band,\n",
    "            include_pixel=True,\n",
    "        )\n",
    "        obj_cat.to_hats(output_path / f\"{target_band}_band\")\n",
    "        print(\"=======FINISHED with band\", target_band, \"========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bea7a6-1c48-4ecb-8a56-4a4a6d3ec545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

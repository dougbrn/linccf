{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Rubin periods\n",
    "\n",
    "This notebook runs the LombScargle for all the variable objects we found in Rubin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsdb\n",
    "import light_curve as licu\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nested_pandas import NestedDtype\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load our objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add the index as a column of the DataFrame so we can later retrieve\n",
    "# all the Rubin data from difference and science imaging\n",
    "variables_df = pd.read_csv(\"periodic_objects.csv\").reset_index()\n",
    "# Transform the DataFrame into a LSDB Catalog\n",
    "variables_catalog = lsdb.from_dataframe(variables_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Rubin data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_nested(df, columns):\n",
    "    return df.assign(\n",
    "        **{\n",
    "            col: df[col].astype(NestedDtype.from_pandas_arrow_dtype(df.dtypes[col]))\n",
    "            for col in columns\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "drp_release = \"w_2025_10\"\n",
    "base_dir = Path(\"/sdf/data/rubin/shared/lsdb_commissioning/hats\")\n",
    "hats_dir = base_dir / drp_release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_lc = lsdb.read_hats(\n",
    "    hats_dir / \"object_lc\",\n",
    "    margin_cache=hats_dir / \"object_lc_5arcs\",\n",
    "    columns=[\"objectId\", \"coord_ra\", \"coord_dec\", \"forcedSource\"],\n",
    ")\n",
    "# We use the `cast_nested` utility method to cast columns into the NestedFrame type\n",
    "object_lc = object_lc.map_partitions(cast_nested, columns=[\"forcedSource\"])\n",
    "# Get the Rubin data for our objects\n",
    "object_lc = variables_catalog.crossmatch(object_lc, radius_arcsec=0.2, suffixes=[\"\", \"\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out invalid light curves\n",
    "\n",
    "Let's drop all observations with nan PSF and objects with light curves of less than 10 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_lc = object_lc.dropna(\n",
    "    subset=[\"forcedSource.psfMag\", \"forcedSource.psfMagErr\"]\n",
    ").dropna(subset=[\"forcedSource\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter to r-band only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_lc = object_lc.query(\"forcedSource.band == 'r'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And make sure we have enough observations per light curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobs = object_lc.reduce(\n",
    "    lambda mjd: {\"nobs\": mjd.size}, \"forcedSource.midpointMjdTai\", meta={\"nobs\": int}\n",
    ")\n",
    "object_lc = object_lc[nobs[\"nobs\"] > 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the LombScargle\n",
    "\n",
    "To compute the periods for each object in the Rubin data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = licu.Extractor(\n",
    "    licu.Periodogram(\n",
    "        peaks=1,\n",
    "        max_freq_factor=10.0,\n",
    "        resolution=50.0,\n",
    "    ),\n",
    "    licu.WeightedMean(),  # Mean magnitude\n",
    "    licu.Eta(),  # Von Neumann's eta statistics\n",
    "    licu.ExcessVariance(),  # Excess variance statistics\n",
    "    licu.Amplitude(),  # 0.5 * [max(mag) - min(mag)]\n",
    ")\n",
    "\n",
    "\n",
    "# light-curve package requires all arrays to be the same dtype.\n",
    "# It also requires the time array to be ordered and to have no duplicates.\n",
    "def extract_features(mjd, mag, magerr, **kwargs):\n",
    "    # We offset date, so we still would have <1 second precision\n",
    "    t = np.asarray(mjd - 60000, dtype=np.float64)\n",
    "    _, sort_index = np.unique(t, return_index=True)\n",
    "    features = extractor(\n",
    "        t[sort_index],\n",
    "        mag[sort_index],\n",
    "        magerr[sort_index],\n",
    "        **kwargs,\n",
    "    )\n",
    "    # Return the features as a dictionary\n",
    "    return dict(zip(extractor.names, features))\n",
    "\n",
    "\n",
    "features = object_lc.reduce(\n",
    "    extract_features,\n",
    "    \"forcedSource.midpointMjdTai\",\n",
    "    \"forcedSource.psfMag\",\n",
    "    \"forcedSource.psfMagErr\",\n",
    "    meta={name: np.float64 for name in extractor.names},\n",
    "    append_columns=True,\n",
    ")\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all calculated Rubin periods to disk\n",
    "features.to_hats(\"rubin_periods\", catalog_name=\"rubin_periods\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

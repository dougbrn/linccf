{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e5a49bb-9251-4b4a-b347-fbef01b945eb",
   "metadata": {},
   "source": [
    "# Fetch data from butler\n",
    "\n",
    "Execution for [2025_04](https://rubinobs.atlassian.net/browse/DM-48556)\n",
    "\n",
    "This notebook uses the butler only to fetch the tracts/patches, and to fetch the URIs of backing parquet files. Those files are read into the hats-import pipeline directly.\n",
    "\n",
    "This is done because many `butler.get` results are too large to fit in the memory of a medium or large RSP notebook instance.\n",
    "\n",
    "Beyond the butler issues, there were additional problems with running the importer on a smaller instance. While these can largely be avoided by running on the dev machines that are available outside notebooks, I think it's a good lesson for how the Rubin data is structured and how we can more efficiently import with our existing tools.\n",
    "\n",
    "Useful material:\n",
    "- LINCC notebooks: https://github.com/lsst-sitcom/linccf\n",
    "- https://github.com/LSSTScienceCollaborations/StackClub/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ab38dd4-ec6d-4d45-9b0d-f41652e9779b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T14:30:05.549281Z",
     "iopub.status.busy": "2025-02-11T14:30:05.548643Z",
     "iopub.status.idle": "2025-02-11T14:30:06.568377Z",
     "shell.execute_reply": "2025-02-11T14:30:06.567909Z",
     "shell.execute_reply.started": "2025-02-11T14:30:05.549264Z"
    }
   },
   "outputs": [],
   "source": [
    "# LSST Science Pipelines (Stack) packages\n",
    "import lsst.daf.butler as dafButler\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15807dad",
   "metadata": {},
   "source": [
    "### Set DRP_VERSION and COLLECTION_TAG\n",
    "\n",
    "1. Update the `DRP_VERSION` and `COLLECTION_TAGS` in *00-set_env.sh*.\n",
    "2. Source the script: ```source 00-set_env.sh```.\n",
    "3. Run Jupyter from the same terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d3a6b07-f916-4e26-8862-ed50f2e669d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T14:30:08.202187Z",
     "iopub.status.busy": "2025-02-11T14:30:08.201451Z",
     "iopub.status.idle": "2025-02-11T14:30:08.205109Z",
     "shell.execute_reply": "2025-02-11T14:30:08.204733Z",
     "shell.execute_reply.started": "2025-02-11T14:30:08.202157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRP_VERSION: w_2025_06\n",
      "COLLECTION_TAG: DM-48810\n"
     ]
    }
   ],
   "source": [
    "# DRP_VERSION = os.environ[\"DRP_VERSION\"]\n",
    "# COLLECTION_TAG = os.environ[\"COLLECTION_TAG\"]\n",
    "DRP_VERSION = \"w_2025_06\"\n",
    "COLLECTION_TAG = \"DM-48810\"\n",
    "print(f\"DRP_VERSION: {DRP_VERSION}\")\n",
    "print(f\"COLLECTION_TAG: {COLLECTION_TAG}\")\n",
    "base_output_dir = Path(f\"/sdf/data/rubin/shared/lsdb_commissioning\")\n",
    "# collections = f\"LSSTComCam/runs/DRP/DP1/{DRP_VERSION}/{COLLECTION_TAG}\"\n",
    "collections = \"LSSTComCam/runs/DRP/DP1/w_2025_06/DM-48810\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d860e7b9-0230-41da-9d5f-aebcb925bb61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T14:30:10.032496Z",
     "iopub.status.busy": "2025-02-11T14:30:10.032059Z",
     "iopub.status.idle": "2025-02-11T14:30:10.084477Z",
     "shell.execute_reply": "2025-02-11T14:30:10.084075Z",
     "shell.execute_reply.started": "2025-02-11T14:30:10.032480Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_dir = base_output_dir / \"raw_delucchi\" / DRP_VERSION\n",
    "\n",
    "paths_dir = raw_dir / \"paths\"\n",
    "refs_dir = raw_dir / \"refs\"\n",
    "sizes_dir = raw_dir / \"sizes\"\n",
    "\n",
    "paths_dir.mkdir(parents=True, exist_ok=True)\n",
    "refs_dir.mkdir(parents=True, exist_ok=True)\n",
    "sizes_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59eeb7e-9f1f-45ef-99c7-6b8b6c1a398d",
   "metadata": {},
   "source": [
    "### Configure Butler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e1a52d8-29d2-46f9-874d-239050c25cf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T14:30:12.139973Z",
     "iopub.status.busy": "2025-02-11T14:30:12.139516Z",
     "iopub.status.idle": "2025-02-11T14:30:12.481367Z",
     "shell.execute_reply": "2025-02-11T14:30:12.480956Z",
     "shell.execute_reply.started": "2025-02-11T14:30:12.139954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/sdf/data/rubin/shared/lsdb_commissioning/raw_delucchi/w_2025_06')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = \"/repo/main\"\n",
    "butler = dafButler.Butler(config, collections=collections)\n",
    "raw_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb1ed0e-7ce5-4f62-8683-204cddce9281",
   "metadata": {},
   "source": [
    "### Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d70d1a98-e5ed-4c05-a279-1c7ac4e99775",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T14:31:21.383620Z",
     "iopub.status.busy": "2025-02-11T14:31:21.383320Z",
     "iopub.status.idle": "2025-02-11T14:31:21.388472Z",
     "shell.execute_reply": "2025-02-11T14:31:21.388060Z",
     "shell.execute_reply.started": "2025-02-11T14:31:21.383603Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_uris_from_butler(dataset_type):\n",
    "    \"\"\"Fetch the parquet URIs for a given dataset\"\"\"\n",
    "    refs = butler.query_datasets(dataset_type)\n",
    "    paths = []\n",
    "    for _, ref in enumerate(tqdm(refs)):\n",
    "        table_path = butler.getURI(dataset_type, dataId=ref.dataId)\n",
    "        paths.append(table_path.path)\n",
    "\n",
    "    print(f\"Found {len(paths)} files for {dataset_type}\")\n",
    "\n",
    "    file_pointer = raw_dir / \"paths\" / f\"{dataset_type}.txt\"\n",
    "    with file_pointer.open(\"w\", encoding=\"utf8\") as _file:\n",
    "        for path in paths:\n",
    "            _file.write(path + \"\\n\")\n",
    "\n",
    "    ref_ids = [ref.dataId.mapping for ref in refs]\n",
    "    ref_frame = pd.DataFrame(ref_ids)\n",
    "    ref_frame.to_csv(raw_dir / \"refs\" / f\"{dataset_type}.csv\", index=False)\n",
    "\n",
    "\n",
    "def get_visits_from_butler():\n",
    "    \"\"\"Downloads the visitTable for LSSTComCam\"\"\"\n",
    "    visits = butler.get(\"visitTable\", dataId={\"instrument\": \"LSSTComCam\"})\n",
    "    parquet_path = raw_dir / \"visits.parquet\"\n",
    "    visits.to_parquet(parquet_path)\n",
    "    print(f\"Saved {len(visits)} visits rows to {parquet_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2519023-4a48-481b-aa6a-3130524376c0",
   "metadata": {},
   "source": [
    "## Fetch all URIs\n",
    "\n",
    "We write the file paths to a simple text file.\n",
    "\n",
    "Example outputs, to give an idea of number of files and total runtime:\n",
    "\n",
    "```\n",
    "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:01<00:00, 20.95it/s]\n",
    "Found 28 files for diaObjectTable_tract\n",
    "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:01<00:00, 22.46it/s]\n",
    "Found 28 files for diaSourceTable_tract\n",
    "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 586/586 [00:27<00:00, 21.54it/s]\n",
    "Found 586 files for forcedSourceOnDiaObjectTable\n",
    "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 605/605 [00:27<00:00, 21.63it/s]\n",
    "Found 605 files for objectTable\n",
    "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 16471/16471 [13:36<00:00, 20.16it/s]\n",
    "Found 16471 files for sourceTable\n",
    "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 605/605 [00:28<00:00, 21.34it/s]\n",
    "Found 605 files for forcedSourceTable\n",
    "```\n",
    "\n",
    "This took a really long time, relative to what I expected, and I'll comment out the invocations.\n",
    "\n",
    "### CONCERN TO DM\n",
    "\n",
    "I'm concerned about the growth of the `sourceTable` in particular. This is already at `16_471` datasets. The result size of `butler.query_datasets(\"sourceTable\")` will soon be too large to handle, and there doesn't appear to be a mechanism in the existing API for pagination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8082b642-2666-4165-8c65-2bc382fdac2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T14:31:23.669442Z",
     "iopub.status.busy": "2025-02-11T14:31:23.668874Z",
     "iopub.status.idle": "2025-02-11T14:32:08.025519Z",
     "shell.execute_reply": "2025-02-11T14:32:08.025183Z",
     "shell.execute_reply.started": "2025-02-11T14:31:23.669421Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 files for diaObjectTable_tract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 28.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 files for diaSourceTable_tract\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 606/606 [00:21<00:00, 28.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 606 files for forcedSourceOnDiaObjectTable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 603/603 [00:20<00:00, 28.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 603 files for forcedSourceTable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "get_uris_from_butler(\"diaObjectTable_tract\")\n",
    "get_uris_from_butler(\"diaSourceTable_tract\")\n",
    "get_uris_from_butler(\"forcedSourceOnDiaObjectTable\")\n",
    "# get_uris_from_butler('objectTable')\n",
    "# get_uris_from_butler('sourceTable')\n",
    "get_uris_from_butler(\"forcedSourceTable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a70cac",
   "metadata": {},
   "source": [
    "## Fetch visits table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ae463ab-2e2e-4aec-8e2e-4bcb21a8c3c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T14:32:10.353811Z",
     "iopub.status.busy": "2025-02-11T14:32:10.353505Z",
     "iopub.status.idle": "2025-02-11T14:32:10.510624Z",
     "shell.execute_reply": "2025-02-11T14:32:10.510254Z",
     "shell.execute_reply.started": "2025-02-11T14:32:10.353794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1787 visits rows to /sdf/data/rubin/shared/lsdb_commissioning/raw_delucchi/w_2025_06/visits.parquet\n"
     ]
    }
   ],
   "source": [
    "get_visits_from_butler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c16d975-0b42-479c-8275-2ce1817f92ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
